{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to False if you don't want to retrain the model\n",
    "train_model = False\n",
    "#Change to True if you want to save the weights from the model\n",
    "save_weights = False\n",
    "epochs = 1 #This model will load previous weights\n",
    "\n",
    "#Set training & test data path\n",
    "train_path = 'Input/train-set/*' \n",
    "test_path = 'Input/vali-set/*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.regularizers import *\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score, precision_recall_fscore_support\n",
    "from keras.models import model_from_json\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import model_from_yaml\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as MPL\n",
    "import cv2\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ryan\\Desktop\\dlass2submission\\Code\\Algorithm\n"
     ]
    }
   ],
   "source": [
    "d = os.getcwd()\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sz = 32\n",
    "channels = 3\n",
    "\n",
    "def print_log(s):\n",
    "    print(\"{} {}\".format(datetime.datetime.now().time(), s))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:08:34.195217 Begin\n",
      "26\n",
      "(32, 32, 3)\n",
      "(1, 32, 32, 3)\n",
      "3072\n",
      "01:08:34.216099 Done!!!\n"
     ]
    }
   ],
   "source": [
    "#obtaining train data\n",
    "\n",
    "      \n",
    "Images = glob.glob(train_path)\n",
    "print_log('Begin')\n",
    "count = 0\n",
    "train_X = []\n",
    "train_Y = []\n",
    "for img in sorted(Images):\n",
    "    \n",
    "    name = int(img[-16:-10][-3:])-1\n",
    "    full_size_image = cv2.imread(img)\n",
    "    image = (cv2.resize(full_size_image, (img_sz,img_sz), interpolation=cv2.INTER_CUBIC))\n",
    "    #gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    gray = image[np.newaxis,:,:]\n",
    "    x = np.ravel(gray)\n",
    "    \n",
    "    train_X.append(gray)\n",
    "    train_Y.append(name)\n",
    "    count+=1\n",
    "    \n",
    "print(count) \n",
    "print(image.shape)\n",
    "print(gray.shape)\n",
    "print(x.shape[0])\n",
    "print_log('Done!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:08:34.260902 Begin\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "#obtaining validation set\n",
    "\n",
    "\n",
    "Images = glob.glob(test_path)\n",
    "print_log('Begin')\n",
    "count = 0\n",
    "test_X = []\n",
    "test_Y = []\n",
    "for img in sorted(Images):\n",
    "    \n",
    "    name = int(img[-16:-10][-3:])-1\n",
    "    full_size_image = cv2.imread(img)\n",
    "    image = (cv2.resize(full_size_image, (img_sz,img_sz), interpolation=cv2.INTER_CUBIC))\n",
    "    #gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    tx = np.ravel(image)\n",
    "    test_X.append(image)\n",
    "    test_Y.append(int(name))\n",
    "    count+=1\n",
    "print(count) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Training data to correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (26, 32, 32, 3)\n",
      "y_train shape: (26, 1)\n",
      "26 train samples\n",
      "26 y_train samples\n"
     ]
    }
   ],
   "source": [
    "train_X=np.array(train_X)\n",
    "train_X.shape = [train_X.shape[0],img_sz,img_sz,channels]\n",
    "##train_X.shape = [37882,128,128,1]\n",
    "x_train = train_X\n",
    "\n",
    "train_Y = np.array(train_Y)\n",
    "train_Y.shape = [train_Y.shape[0],1]\n",
    "y_train = train_Y\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(y_train.shape[0], 'y_train samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Test data to correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (26, 32, 32, 3)\n",
      "y_train shape: (26, 1)\n",
      "26 test samples\n",
      "26 y_test samples\n"
     ]
    }
   ],
   "source": [
    "test_X=np.array(test_X)\n",
    "#test_X.shape = [6262,128,128,1]\n",
    "test_X.shape = [test_X.shape[0],img_sz,img_sz,channels]\n",
    "x_test = test_X\n",
    "\n",
    "test_Y = np.array(test_Y)\n",
    "test_Y.shape = [test_Y.shape[0],1]\n",
    "y_test = test_Y\n",
    "\n",
    "print('x_train shape:', x_test.shape)\n",
    "print('y_train shape:', y_test.shape)\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print(y_test.shape[0], 'y_test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This sets the conditions of the run for the CNN network.\n",
    "batch_size = 128\n",
    "num_classes = 62\n",
    "\n",
    "data_augmentation = False\n",
    "x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert label data to shape needed\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This builds the CNN model structure around the VGG16 model, sets pooling, activations etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               102600    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 62)                12462     \n",
      "=================================================================\n",
      "Total params: 14,830,550\n",
      "Trainable params: 14,830,150\n",
      "Non-trainable params: 400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "opt = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "initial_model = VGG16(weights='imagenet', include_top=False)\n",
    "input = Input(shape=(img_sz, img_sz, 3), name='image_input')\n",
    "x = Flatten()(initial_model(input))\n",
    "x = Dense(200, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(num_classes,activation='softmax')(x)\n",
    "model = Model(inputs=input, outputs=x)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,      \n",
    "              metrics=['acc'])  \n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This loads the weights of the previously trained model\n",
    "# model.load_weights('Models/model.h5')\n",
    "# model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Select optimiser and compile model\n",
    "# opt = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=opt,      \n",
    "#               metrics=['acc'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert values to float and between 0 - 1 \n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Run the model, if statement allows to use or not use data augmentation\n",
    "if train_model:\n",
    "    total_start_time = time.time()\n",
    "    if not data_augmentation:\n",
    "         model.fit(x_train, y_train,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  validation_data=(x_test, y_test),\n",
    "                  shuffle=True)\n",
    "    else:\n",
    "        datagen = ImageDataGenerator(\n",
    "            zca_whitening=True,  \n",
    "            rotation_range=0,\n",
    "            width_shift_range=0.0, \n",
    "            height_shift_range=0.0, \n",
    "            horizontal_flip=False,\n",
    "            vertical_flip=False)\n",
    "        datagen.fit(x_train)\n",
    "\n",
    "        model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                         batch_size=batch_size),\n",
    "                            steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                            epochs=epochs,\n",
    "    validation_data=(x_test, y_test))\n",
    "    print('Time Check',(time.time() - total_start_time)/60,'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_weights:\n",
    "#serialize model to YAML\n",
    "    model_yaml = model.to_yaml()\n",
    "    with open(\"Models/model_new.yaml\", \"w\") as yaml_file:\n",
    "        yaml_file.write(model_yaml)    \n",
    "\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"Models/model_new.h5\")\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s\n",
      "\n",
      "Test accuracy is 96.15384340286255%\n"
     ]
    }
   ],
   "source": [
    "#Evaluate model against test set\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"\\nTest accuracy is {}%\".format(100.0*score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict\n",
    "preds = model.predict(x_test)\n",
    "actual = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#flatten to the argmax of the probabilities to choose the option and compare\n",
    "predict = []\n",
    "for i in preds:\n",
    "    predict.append(np.argmax(i))\n",
    "    #print(np.argmax(i))\n",
    "print(predict[0])\n",
    "\n",
    "actual = []\n",
    "for i in y_test:\n",
    "    actual.append(np.argmax(i))\n",
    "    #print(np.argmax(i))\n",
    "print(actual[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25,  1],\n",
       "       [ 0,  0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(actual, predict)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Model)                multiple                  14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               102600    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 62)                12462     \n",
      "=================================================================\n",
      "Total params: 14,830,550\n",
      "Trainable params: 14,830,150\n",
      "Non-trainable params: 400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#View the model struture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creates seaborn confusiono matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (20,14), fontsize=14):\n",
    " \n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = []\n",
    "for x in range (0,62):\n",
    "    lab.append(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_confusion_matrix(conf_matrix,lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
